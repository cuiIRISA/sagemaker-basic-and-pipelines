{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sagemaker Pipelines\n",
    "\n",
    "Amazon SageMaker Pipelines is the purpose-built, easy-to-use continuous integration and continuous delivery (CI/CD) service for machine learning (ML). \n",
    "\n",
    "- SageMaker Integration: SageMaker Pipelines is a fully managed service, which means that it creates and manages resources for you\n",
    "- SageMaker Python SDK Integration: you can create your pipelines programmatically using a high-level Python interface that you might already be familiar with\n",
    "- SageMaker Studio Integration: offers an environment to manage the end-to-end SageMaker Pipelines experience\n",
    "- Data Lineage Tracking: lets you analyze where the data came from, where it was used as an input, and the outputs that were generated from it\n",
    "\n",
    "To learn more about SageMaker Pipelines, please check\n",
    "\n",
    "* Doc https://docs.aws.amazon.com/sagemaker/latest/dg/pipelines.html\n",
    "* SDK https://sagemaker.readthedocs.io/en/stable/workflows/pipelines/sagemaker.workflow.pipelines.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import json\n",
    "import boto3\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "sm_client = boto3.client('sagemaker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eu-west-1\n",
      "sagemaker-eu-west-1-707684582322\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the default bucket\n",
    "sagemaker_session = sagemaker.Session()\n",
    "bucket = sagemaker_session.default_bucket()\n",
    "region = sagemaker_session.boto_region_name\n",
    "print(region)\n",
    "print(bucket)\n",
    "role = get_execution_role()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before executing this step, we assume that you have already created a SageMaker Project. \n",
    "\n",
    "A SageMaker project is an AWS Service Catalog provisioned product that enables you to easily create an end-to-end ML solution. Each SageMaker project has a unique name and ID that are passed to all SageMaker and AWS resources created in the project. By using the name and ID, you can view all entities associated with your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model package group name: mlops-cicd-demo-p-1llgzzxekxpq\n"
     ]
    }
   ],
   "source": [
    "project_name = \"Replace with your sagemaker project name here\"\n",
    "# project_name = \"mlops-cicd-demo\"\n",
    "\n",
    "project_id = sm_client.describe_project(ProjectName=project_name)['ProjectId']\n",
    "\n",
    "model_package_group_name = project_name + '-' + project_id\n",
    "print(\"Model package group name: %s\" % model_package_group_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline input parameters\n",
    "\n",
    "You can introduce variables into your pipeline definition using parameters. Parameters that you define can be referenced throughout your pipeline definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.parameters import ParameterInteger, ParameterString\n",
    "\n",
    "training_instance_type = ParameterString(\n",
    "    name=\"TrainingInstanceType\",\n",
    "    default_value=\"ml.m5.xlarge\"\n",
    ")\n",
    "\n",
    "training_instance_count = ParameterInteger(\n",
    "    name=\"TrainingInstanceCount\",\n",
    "    default_value=1\n",
    ")\n",
    "\n",
    "input_raw_data = ParameterString(\n",
    "    name=\"InputRawData\",\n",
    "    default_value='s3://{}/sagemaker/xgboostcontainer/raw-data'.format(bucket)\n",
    ")\n",
    "\n",
    "input_train_data = ParameterString(\n",
    "    name=\"InputDataTrain\",\n",
    "    default_value='s3://{}/sagemaker/xgboostcontainer/processed/train'.format(bucket)\n",
    ")\n",
    "\n",
    "input_test_data = ParameterString(\n",
    "    name=\"InputDataTest\",\n",
    "    default_value='s3://{}/sagemaker/xgboostcontainer/processed/test'.format(bucket)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing Step\n",
    "\n",
    "Amazon SageMaker Processing allows you to run steps for data pre- or post-processing, feature engineering, data validation, or model evaluation workloads on Amazon SageMaker.\n",
    "\n",
    "A processing step requires a processor, a Python script that defines the processing code, outputs for processing, and job arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "role = get_execution_role()\n",
    "sklearn_processor = SKLearnProcessor(framework_version='0.20.0',\n",
    "                                     role=role,\n",
    "                                     instance_type=training_instance_type,\n",
    "                                     instance_count=training_instance_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
    "from sagemaker.workflow.steps import ProcessingStep\n",
    "\n",
    "step_process = ProcessingStep(\n",
    "    name=\"BostonHousingDropColumns\",\n",
    "    processor=sklearn_processor,\n",
    "    inputs=[\n",
    "      ProcessingInput(source=input_raw_data, destination=\"/opt/ml/processing/input\"),  \n",
    "    ],\n",
    "    outputs=[ProcessingOutput(output_name='xgboost_train_data',\n",
    "                              source='/opt/ml/processing/output/train',\n",
    "                              destination = input_train_data),\n",
    "             ProcessingOutput(output_name='xgboost_test_data',\n",
    "                              source='/opt/ml/processing/output/test',\n",
    "                              destination = input_test_data)],\n",
    "    code=\"preprocessing.py\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Step \n",
    "\n",
    "You use a training step to create a training job to train a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.image_uris import retrieve \n",
    "from sagemaker.session import Session\n",
    "\n",
    "# this line automatically looks for the XGBoost image URI and builds an XGBoost container.\n",
    "# specify the repo_version depending on your preference.\n",
    "container = retrieve(region=boto3.Session().region_name,\n",
    "                          framework='xgboost', \n",
    "                          version='1.0-1')\n",
    "print(container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize hyperparameters\n",
    "hyperparameters = {\n",
    "        \"max_depth\":\"10\",\n",
    "        \"eta\":\"0.2\",\n",
    "        \"gamma\":\"4\",\n",
    "        \"min_child_weight\":\"6\",\n",
    "        \"subsample\":\"0.7\",\n",
    "        \"objective\":\"reg:squarederror\",\n",
    "        \"num_round\":\"200\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct a SageMaker estimator that calls the xgboost-container\n",
    "estimator = sagemaker.estimator.Estimator(image_uri=container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=role,\n",
    "                                          instance_count=1, \n",
    "                                          instance_type='ml.m5.2xlarge')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A training step requires an estimator, and training and validation data inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.inputs import TrainingInput\n",
    "from sagemaker.workflow.steps import TrainingStep\n",
    "\n",
    "step_train = TrainingStep(\n",
    "    name=\"TrainingXgBoost\",\n",
    "    estimator=estimator,\n",
    "    inputs={\n",
    "        \"train\": TrainingInput(s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"xgboost_train_data\"].S3Output.S3Uri, content_type=\"text/csv\"),\n",
    "        \"validation\": TrainingInput(s3_data=step_process.properties.ProcessingOutputConfig.Outputs[\"xgboost_test_data\"].S3Output.S3Uri, content_type=\"text/csv\"\n",
    "        )\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Register step that will add a new version to the Model Registry\n",
    "\n",
    "You use a RegisterModel step to register a model to a model group.\n",
    "\n",
    "A RegisterModel step requires an estimator, model data output from training, and a model package group name to associate the model package with.\n",
    "\n",
    "With this step, you can create a model group that tracks all of the models that you train to solve a particular problem. You can then register each model you train and the model registry adds it to the model group as a new model version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.workflow.step_collections import RegisterModel\n",
    "\n",
    "# NOTE: model_approval_status is not available as arg in service dsl currently\n",
    "step_register = RegisterModel(\n",
    "    name=\"RegisterXgBoostModel\",\n",
    "    estimator=estimator,\n",
    "    model_data=step_train.properties.ModelArtifacts.S3ModelArtifacts,\n",
    "    content_types=[\"text/csv\"],\n",
    "    response_types=[\"text/csv\"],\n",
    "    inference_instances=[\"ml.t2.medium\", \"ml.m5.large\"],\n",
    "    transform_instances=[\"ml.m5.large\"],\n",
    "    model_package_group_name=model_package_group_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, we can create the pipeline\n",
    "\n",
    "This pipeline definition encodes a pipeline using a directed acyclic graph (DAG). This DAG gives information on the requirements for and relationships between each step of your pipeline. \n",
    "\n",
    "The structure of a pipeline's DAG is determined by the data dependencies between steps (defined within each step previously). These data dependencies are created when the properties of a step's output are passed as the input to another step. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from botocore.exceptions import ClientError, ValidationError\n",
    "from sagemaker.workflow.pipeline import Pipeline\n",
    "\n",
    "# NOTE:\n",
    "# condition steps have issues in service so we go straight to step_register\n",
    "pipeline_name = \"Replace by your pipeline name\"\n",
    "# pipeline_name = \"XgBoost-Pipelines-2\"\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    name=pipeline_name,\n",
    "    parameters=[\n",
    "        training_instance_type,\n",
    "        training_instance_count,\n",
    "        input_raw_data,\n",
    "        input_train_data,\n",
    "        input_test_data\n",
    "    ],\n",
    "    steps=[step_process,step_train, step_register],\n",
    "    sagemaker_session=sagemaker_session,\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = pipeline.create(role_arn=role)\n",
    "except ClientError as e:\n",
    "    error = e.response[\"Error\"]\n",
    "    if error[\"Code\"] == \"ValidationError\" and \"Pipeline names must be unique within\" in error[\"Message\"]:\n",
    "        print(error[\"Message\"])\n",
    "        response = pipeline.describe()\n",
    "    else:\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_arn = response[\"PipelineArn\"]\n",
    "print(pipeline_arn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And then, run it\n",
    "\n",
    "After youâ€™ve created a pipeline definition using the SageMaker Python SDK, you can submit it to SageMaker to start your execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_response = pipeline.start(parameters={\n",
    "    \"TrainingInstanceCount\": \"1\"\n",
    "})\n",
    "\n",
    "pipeline_execution_arn = start_response.arn\n",
    "print(pipeline_execution_arn)\n",
    "\n",
    "while True:\n",
    "    resp = sm_client.describe_pipeline_execution(PipelineExecutionArn=pipeline_execution_arn)\n",
    "    if resp['PipelineExecutionStatus'] == 'Executing':\n",
    "        print('Running...')\n",
    "    else:\n",
    "        print(resp['PipelineExecutionStatus'], pipeline_execution_arn)\n",
    "        break\n",
    "    time.sleep(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally, approve the model to kick-off the deployment process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all packages and select the latest one\n",
    "packages = sm_client.list_model_packages(ModelPackageGroupName=model_package_group_name)['ModelPackageSummaryList']\n",
    "packages = sorted(packages, key=lambda x: x['CreationTime'], reverse=True)\n",
    "packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can either manually approve the model or using sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# latest_model_package_arn = packages[0]['ModelPackageArn']\n",
    "# model_package_update_response = sm_client.update_model_package(\n",
    "#    ModelPackageArn=latest_model_package_arn,\n",
    "#    ModelApprovalStatus=\"Approved\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Done! :) Let's open the CodePipeline console and get some popcorn to watch"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
